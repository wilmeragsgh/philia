{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrK-ilWG-Xj9",
    "outputId": "cf9ad850-2ccb-4e17-e642-83ce94e936f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.48.30.82:8470']\n",
      "INFO:tensorflow:Initializing the TPU system: grpc://10.48.30.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.48.30.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import os\n",
    "from shutil import rmtree\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhKGndCm-cxR",
    "outputId": "114ceada-d4b1-4ef6-95e4-7e6c64acc70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-23 04:01:28--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-05-23 04:01:28--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-05-23 04:01:29--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove6b.zip’\n",
      "\n",
      "glove6b.zip         100%[===================>] 822.24M  5.14MB/s    in 2m 40s  \n",
      "\n",
      "2021-05-23 04:04:09 (5.14 MB/s) - ‘glove6b.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove6b.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "max_len = 500\n",
    "top_words = 5000\n",
    "max_words = 10000\n",
    "path_to_data = './'\n",
    "glove_dir = './'\n",
    "embedding_dim = 300\n",
    "embedding_file_name = 'glove.6B.300d.txt'\n",
    "\n",
    "!wget -O glove6b.zip http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove6b.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0E748lST-hj2",
    "outputId": "483ed412-89f4-4373-9fb3-2080ef7108ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it feels like hitting to blank wall when i se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont you feel so.. its a wonder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  emotion\n",
       "0  I remember going to see the fireworks with my ...        1\n",
       "1                This was a best friend. I miss her.        1\n",
       "2                                 We no longer talk.        1\n",
       "3   it feels like hitting to blank wall when i se...        1\n",
       "4                   dont you feel so.. its a wonder         1"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data = pd.read_csv(\"emotion_data_bin.csv\")\n",
    "#empathy_data = pd.read_csv(\"empaty_assessment.csv\")\n",
    "emotion_data = emotion_data[[\"utterance\", \"emotion\"]]\n",
    "emotion_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fDtu-owjFxMi"
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(emotion_data[\"utterance\"], emotion_data[\"context\"], test_size=0.33, random_state=42, stratify=emotion_data[\"context\"])\n",
    "\n",
    "labels = emotion_data[\"emotion\"]#pd.get_dummies(emotion_data['emotion']).values\n",
    "texts = emotion_data.utterance\n",
    "data = emotion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UQmNfajUGFBm"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)                \n",
    "word_index = tokenizer.word_index   \n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "labels = np.asarray(labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dypsLeaNIM8_"
   },
   "outputs": [],
   "source": [
    "X_train = data\n",
    "Y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRpnauuHIXUC",
    "outputId": "5daa6a14-7400-49fb-a5fa-23e8451f4abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# create dictionary to map word -> embedding vector\n",
    "embeddings_index = {}                                        \n",
    "f = open(os.path.join(glove_dir, embedding_file_name))\n",
    "i = 0\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index)) \n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "hyWl4a17IY9u"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = preprocessing.scale(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_aobMmKVDuec"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    beta_sqr = (1.2**2)\n",
    "    return (1 + beta_sqr) *((precision*recall)/((beta_sqr * precision)+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "gmL8LJkCIbE1"
   },
   "outputs": [],
   "source": [
    "def create_model(max_words, embedding_dim, max_len, embedding_matrix):\n",
    "    hidden_dim = 300 \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "    model.add(Bidirectional(LSTM(hidden_dim)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))# Dense(32, activation='softmax'))\n",
    "    \n",
    "    # Load embeddings\n",
    "    model.layers[0].set_weights([embedding_matrix])\n",
    "    model.layers[0].trainable = False   \n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', f1_m])#categorical_crossentropy\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKHVRW9FbkOb",
    "outputId": "481ca9ff-863e-4921-a35f-f794158428c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1774/1774 [==============================] - 141s 76ms/step - loss: 0.2710 - acc: 0.8780 - f1_m: 0.9092\n",
      "Epoch 2/15\n",
      "1774/1774 [==============================] - 134s 76ms/step - loss: 0.1680 - acc: 0.9301 - f1_m: 0.9446\n",
      "Epoch 3/15\n",
      "1774/1774 [==============================] - 134s 76ms/step - loss: 0.1248 - acc: 0.9504 - f1_m: 0.9615\n",
      "Epoch 4/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0903 - acc: 0.9637 - f1_m: 0.9693\n",
      "Epoch 5/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0638 - acc: 0.9751 - f1_m: 0.9776\n",
      "Epoch 6/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0498 - acc: 0.9807 - f1_m: 0.9830\n",
      "Epoch 7/15\n",
      "1774/1774 [==============================] - 134s 76ms/step - loss: 0.0400 - acc: 0.9855 - f1_m: 0.9863\n",
      "Epoch 8/15\n",
      "1774/1774 [==============================] - 134s 76ms/step - loss: 0.0330 - acc: 0.9875 - f1_m: 0.9888\n",
      "Epoch 9/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0288 - acc: 0.9887 - f1_m: 0.9883\n",
      "Epoch 10/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0264 - acc: 0.9899 - f1_m: 0.9899\n",
      "Epoch 11/15\n",
      "1774/1774 [==============================] - 136s 77ms/step - loss: 0.0229 - acc: 0.9917 - f1_m: 0.9907\n",
      "Epoch 12/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0239 - acc: 0.9912 - f1_m: 0.9901\n",
      "Epoch 13/15\n",
      "1774/1774 [==============================] - 135s 76ms/step - loss: 0.0250 - acc: 0.9909 - f1_m: 0.9909\n",
      "Epoch 14/15\n",
      "1774/1774 [==============================] - 136s 77ms/step - loss: 0.0204 - acc: 0.9925 - f1_m: 0.9922\n",
      "Epoch 15/15\n",
      "1774/1774 [==============================] - 136s 77ms/step - loss: 0.0232 - acc: 0.9918 - f1_m: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# Enter TPU env:\n",
    "with tpu_strategy.scope():\n",
    "    # instantiate model\n",
    "    model = create_model(max_words, embedding_dim, max_len, embedding_matrix)     \n",
    "    # train model\n",
    "    history = model.fit(X_train, Y_train, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "nXhIPw34g0Gf"
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"emotion_data_bin_valid.csv\")\n",
    "\n",
    "labels = valid[\"emotion\"]#pd.get_dummies(valid['context']).values\n",
    "texts = valid.utterance\n",
    "data = valid\n",
    "sequences = tokenizer.texts_to_sequences(texts)                \n",
    "word_index = tokenizer.word_index   \n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "labels = np.asarray(labels)   \n",
    "X_test = data\n",
    "Y_test = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yCidf8d_Qe0",
    "outputId": "c11dbf62-dd46-4763-ec83-213c6cd05d25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8339    0.8229    0.8283      1592\n",
      "           1     0.9557    0.9588    0.9572      6340\n",
      "\n",
      "    accuracy                         0.9315      7932\n",
      "   macro avg     0.8948    0.8908    0.8928      7932\n",
      "weighted avg     0.9312    0.9315    0.9314      7932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter TPU env:\n",
    "with tpu_strategy.scope():\n",
    "    # print fold classification report\n",
    "    y_hat = model.predict_classes(X_test, verbose = 0)\n",
    "    y_hat_classes = [y[0] for y in y_hat]\n",
    "    y_test_classes = Y_test\n",
    "\n",
    "print(classification_report(y_test_classes, y_hat_classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HYlggfki8j8",
    "outputId": "e8d076e1-c003-409a-8106-6caea63a2d64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82733701, 0.95753296])"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test_classes,y_hat_classes, beta=1.2)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "kjZ4qa9sePKC"
   },
   "outputs": [],
   "source": [
    "model.save('BiLSTM_emotion_detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoPFn1m8GOfb"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "mbAhuGZeHCjt"
   },
   "outputs": [],
   "source": [
    "emotion_data = pd.read_csv(\"emotion_data_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "kRd3pqF4GubO"
   },
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(emotion_data['context']).values\n",
    "texts = emotion_data.utterance\n",
    "data = emotion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9VYYv278HBE4"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)                \n",
    "word_index = tokenizer.word_index   \n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "HYJSDfwyHSc_"
   },
   "outputs": [],
   "source": [
    "X_train = data\n",
    "Y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "KtwA7oOOIDEb"
   },
   "outputs": [],
   "source": [
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    beta_sqr = 1\n",
    "    return (1 + beta_sqr) *((precision*recall)/((beta_sqr * precision)+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ZcRn-PATGNkf"
   },
   "outputs": [],
   "source": [
    "def create_model(max_words, embedding_dim, max_len, embedding_matrix):\n",
    "    hidden_dim = 300 \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "    model.add(Bidirectional(LSTM(hidden_dim)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='softmax'))# Dense(32, activation='softmax'))\n",
    "    \n",
    "    # Load embeddings\n",
    "    model.layers[0].set_weights([embedding_matrix])\n",
    "    model.layers[0].trainable = False   \n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', f1_m])#categorical_crossentropy\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4IisMDkHVsQ",
    "outputId": "e2649b84-63a3-4fe2-e195-241fe891824d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1373/1373 [==============================] - 111s 76ms/step - loss: 3.3414 - acc: 0.0886 - f1_m: 0.0037\n",
      "Epoch 2/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 2.7324 - acc: 0.2426 - f1_m: 0.0820\n",
      "Epoch 3/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 2.3954 - acc: 0.3239 - f1_m: 0.1792\n",
      "Epoch 4/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 2.1575 - acc: 0.3801 - f1_m: 0.2490\n",
      "Epoch 5/15\n",
      "1373/1373 [==============================] - 104s 76ms/step - loss: 1.9341 - acc: 0.4381 - f1_m: 0.3182\n",
      "Epoch 6/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 1.7298 - acc: 0.4890 - f1_m: 0.3884\n",
      "Epoch 7/15\n",
      "1373/1373 [==============================] - 104s 76ms/step - loss: 1.5844 - acc: 0.5267 - f1_m: 0.4386\n",
      "Epoch 8/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 1.4205 - acc: 0.5718 - f1_m: 0.5030\n",
      "Epoch 9/15\n",
      "1373/1373 [==============================] - 104s 75ms/step - loss: 1.3045 - acc: 0.6059 - f1_m: 0.5457\n",
      "Epoch 10/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 1.1929 - acc: 0.6375 - f1_m: 0.5833\n",
      "Epoch 11/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 1.1155 - acc: 0.6580 - f1_m: 0.6113\n",
      "Epoch 12/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 1.0327 - acc: 0.6821 - f1_m: 0.6470\n",
      "Epoch 13/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 0.9841 - acc: 0.6935 - f1_m: 0.6648\n",
      "Epoch 14/15\n",
      "1373/1373 [==============================] - 103s 75ms/step - loss: 0.9278 - acc: 0.7082 - f1_m: 0.6839\n",
      "Epoch 15/15\n",
      "1373/1373 [==============================] - 104s 75ms/step - loss: 0.8790 - acc: 0.7218 - f1_m: 0.6997\n"
     ]
    }
   ],
   "source": [
    "# Enter TPU env:\n",
    "with tpu_strategy.scope():\n",
    "    # instantiate model\n",
    "    model = create_model(max_words, embedding_dim, max_len, embedding_matrix)     \n",
    "    # train model\n",
    "    history = model.fit(X_train, Y_train, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "PgkhJjduHd92"
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"emotion_data_class_valid.csv\")\n",
    "\n",
    "labels = pd.get_dummies(valid['context']).values\n",
    "texts = valid.utterance\n",
    "data = valid\n",
    "sequences = tokenizer.texts_to_sequences(texts)                \n",
    "word_index = tokenizer.word_index   \n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "labels = np.asarray(labels)   \n",
    "X_test = data\n",
    "Y_test = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgBBL04PHmMv",
    "outputId": "eb8c3084-8ce6-4962-bed6-f8373aff76e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1828    0.1635    0.1726       208\n",
      "           1     0.1173    0.1173    0.1173       196\n",
      "           2     0.2564    0.2128    0.2326       282\n",
      "           3     0.1987    0.1813    0.1896       171\n",
      "           4     0.1630    0.2022    0.1805       183\n",
      "           5     0.1257    0.1250    0.1254       176\n",
      "           6     0.1583    0.1341    0.1452       164\n",
      "           7     0.2088    0.2275    0.2178       167\n",
      "           8     0.2659    0.3349    0.2965       212\n",
      "           9     0.2615    0.2864    0.2734       199\n",
      "          10     0.1782    0.1771    0.1777       175\n",
      "          11     0.1137    0.1116    0.1127       215\n",
      "          12     0.3907    0.3155    0.3491       187\n",
      "          13     0.3558    0.3394    0.3474       218\n",
      "          14     0.2115    0.2133    0.2124       225\n",
      "          15     0.1688    0.1140    0.1361       114\n",
      "          16     0.1961    0.1676    0.1807       179\n",
      "          17     0.1694    0.1802    0.1746       172\n",
      "          18     0.2298    0.3540    0.2787       161\n",
      "          19     0.1747    0.2128    0.1918       188\n",
      "          20     0.3357    0.2078    0.2567       231\n",
      "          21     0.3094    0.2745    0.2909       204\n",
      "          22     0.1902    0.1823    0.1862       192\n",
      "          23     0.4050    0.4516    0.4270       217\n",
      "          24     0.3315    0.3296    0.3305       179\n",
      "          25     0.3430    0.2719    0.3033       217\n",
      "          26     0.1771    0.1818    0.1794       187\n",
      "          27     0.2291    0.2716    0.2485       232\n",
      "          28     0.2697    0.2540    0.2616       189\n",
      "          29     0.2512    0.3107    0.2778       338\n",
      "          30     0.2154    0.1474    0.1750       190\n",
      "          31     0.1990    0.2384    0.2169       172\n",
      "\n",
      "    accuracy                         0.2328      6340\n",
      "   macro avg     0.2307    0.2279    0.2271      6340\n",
      "weighted avg     0.2353    0.2328    0.2318      6340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter TPU env:\n",
    "with tpu_strategy.scope():\n",
    "    # print fold classification report\n",
    "    y_hat = model.predict(X_test, verbose = 0)\n",
    "    y_hat_classes = tf.argmax(y_hat, axis=1).numpy()\n",
    "    y_test_classes = tf.argmax(Y_test, axis=1).numpy()\n",
    "\n",
    "print(classification_report(y_test_classes, y_hat_classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "NG-ugVpFO_gf"
   },
   "outputs": [],
   "source": [
    "model.save('BiLSTM_emotion_class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3WLS3muP3Qv"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "as2aeVxuQ4po",
    "outputId": "f0ca130d-835e-44ac-a259-0e3ecb4ee15b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_utterance</th>\n",
       "      <th>min_empathy_eval</th>\n",
       "      <th>min_relevance_eval</th>\n",
       "      <th>min_understandability_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentimental - Was this a friend you were in lo...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentimental - Where has she gone?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentimental - Oh was this something that happe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afraid - Oh ya? I don't really see how</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afraid - I do actually hit blank walls a lot o...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   context_utterance  ...  min_understandability_eval\n",
       "0  sentimental - Was this a friend you were in lo...  ...                           5\n",
       "1                  sentimental - Where has she gone?  ...                           5\n",
       "2  sentimental - Oh was this something that happe...  ...                           5\n",
       "3             afraid - Oh ya? I don't really see how  ...                           4\n",
       "4  afraid - I do actually hit blank walls a lot o...  ...                           4\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data = pd.read_csv(\"empathy_data_assessment.csv\")\n",
    "emotion_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "OHwYLeDMP4OK"
   },
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(emotion_data[\"min_empathy_eval\"]).values\n",
    "texts = emotion_data[\"context_utterance\"]\n",
    "data = emotion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "to0i2ZnAfdrO"
   },
   "outputs": [],
   "source": [
    "emotion_data = emotion_data[emotion_data[\"min_empathy_eval\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "_bENdKEcRT1O"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)                \n",
    "word_index = tokenizer.word_index   \n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "eval = np.asarray(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "7frDLORERf1F"
   },
   "outputs": [],
   "source": [
    "X_train = data\n",
    "Y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "XF5aHngYRjQv"
   },
   "outputs": [],
   "source": [
    "def create_model(max_words, embedding_dim, max_len, embedding_matrix):\n",
    "    hidden_dim = 300 \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "    model.add(Bidirectional(LSTM(hidden_dim)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    # Load embeddings\n",
    "    model.layers[0].set_weights([embedding_matrix])\n",
    "    model.layers[0].trainable = False   \n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', f1_m])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REU4CHw-SEcy",
    "outputId": "b3bd759c-4311-4697-a4f8-c18a6faf96b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "1240/1240 [==============================] - 102s 77ms/step - loss: 1.0023 - acc: 0.6459 - f1_m: 0.6279\n",
      "Epoch 2/14\n",
      "1240/1240 [==============================] - 93s 75ms/step - loss: 0.9664 - acc: 0.6494 - f1_m: 0.6420\n",
      "Epoch 3/14\n",
      "1240/1240 [==============================] - 94s 75ms/step - loss: 0.9496 - acc: 0.6502 - f1_m: 0.6378\n",
      "Epoch 4/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.9066 - acc: 0.6573 - f1_m: 0.6401\n",
      "Epoch 5/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.8662 - acc: 0.6674 - f1_m: 0.6473\n",
      "Epoch 6/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.8147 - acc: 0.6810 - f1_m: 0.6577\n",
      "Epoch 7/14\n",
      "1240/1240 [==============================] - 94s 75ms/step - loss: 0.7342 - acc: 0.7144 - f1_m: 0.6921\n",
      "Epoch 8/14\n",
      "1240/1240 [==============================] - 93s 75ms/step - loss: 0.6688 - acc: 0.7357 - f1_m: 0.7204\n",
      "Epoch 9/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.6044 - acc: 0.7651 - f1_m: 0.7518\n",
      "Epoch 10/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.5406 - acc: 0.7877 - f1_m: 0.7785\n",
      "Epoch 11/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.4776 - acc: 0.8115 - f1_m: 0.8045\n",
      "Epoch 12/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.4307 - acc: 0.8342 - f1_m: 0.8283\n",
      "Epoch 13/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.3946 - acc: 0.8442 - f1_m: 0.8399\n",
      "Epoch 14/14\n",
      "1240/1240 [==============================] - 94s 76ms/step - loss: 0.3604 - acc: 0.8620 - f1_m: 0.8568\n"
     ]
    }
   ],
   "source": [
    "# Enter TPU env:\n",
    "with tpu_strategy.scope():\n",
    "    # instantiate model\n",
    "    model = create_model(max_words, embedding_dim, max_len, embedding_matrix)     \n",
    "    # train model\n",
    "    history = model.fit(X_train, Y_train, epochs = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "-sEo7qvSWOsG"
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"empathy_data_assessment_valid.csv\")\n",
    "\n",
    "labels = pd.get_dummies(valid[\"min_empathy_eval\"]).values\n",
    "texts = valid[\"context_utterance\"]\n",
    "data = valid\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)                \n",
    "word_index = tokenizer.word_index   \n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "labels = np.asarray(labels)   \n",
    "X_test = data\n",
    "Y_test = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-URCUI8fIKX",
    "outputId": "e4b1b4dc-61ab-467c-9fc0-cc99f7fb2553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1972\n",
       "4    1063\n",
       "3     245\n",
       "2      65\n",
       "1      56\n",
       "Name: min_empathy_eval, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[\"min_empathy_eval\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6la6RKife5rK",
    "outputId": "d06b128f-07a6-4d94-bc5d-caeafae51d51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZr_1r7vXdVs",
    "outputId": "6f5d3da0-e083-4b41-9a9a-5fe8cb336d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        56\n",
      "           1     0.0769    0.0154    0.0256        65\n",
      "           2     0.1400    0.0571    0.0812       245\n",
      "           3     0.3591    0.1966    0.2541      1063\n",
      "           4     0.5932    0.8119    0.6855      1972\n",
      "\n",
      "    accuracy                         0.5366      3401\n",
      "   macro avg     0.2338    0.2162    0.2093      3401\n",
      "weighted avg     0.4677    0.5366    0.4832      3401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter TPU env:\n",
    "with tpu_strategy.scope():\n",
    "    # print fold classification report\n",
    "    y_hat = model.predict(X_test, verbose = 0)\n",
    "    y_hat_classes = tf.argmax(y_hat, axis=1).numpy()\n",
    "    y_test_classes = tf.argmax(Y_test, axis=1).numpy()\n",
    "\n",
    "print(classification_report(y_test_classes, y_hat_classes, digits=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
